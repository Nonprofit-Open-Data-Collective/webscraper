create_table <- function( input ){
if( length( input ) < 1 ){
stop( "Must Input at Least 1 URL" )
}
if( length( input )== 1 ){
URL.frame <- create_table_01( input )
}else{
URL.frame <- data.frame()
for( i in 1:length( input ) ){
URL.table <- create_table_01( input[i] )
URL.frame <- rbind( URL.frame, URL.table )
}
return(URL.frame)
}
x <- Null
x <- NULL
length(x)
create_table(x)
create_table(one)
create_table(two)
xx <- create_table(two)
View(xx)
roxygen2::roxygenize()
library(webscraper)
load_test_urls()
one <- sample.urls$ORGURL[3]
two <- sample.urls$ORGURL[3:4]
five <- sample.urls$ORGURL[3:8]
five <- sample.urls$ORGURL[3:7]
table_one <- create_table(one)
table_two <- create_table(two)
table_five <- create_table(five)
roxygen2::roxygenize()
library(webscraper)
load_test_urls()
one <- sample.urls$ORGURL[5]
save <- create_table(one)
getNodes(save$normalized_URL[1])
nodes <- getNodes(save$normalized_URL[1])
xml2::read_html( save$normalized_URL[1] )
get_p_node_data(save$normalized_URL[1])
View(save)
library(webscraper)
load_test_urls()
test <- sample.urls$ORGURL[5]
table <- create_table(test)
two <- table$normalized_URL[1]
getNodes(two)
html_page <- xml2::read_html( two )
View(html_page)
html_page %>%  # read in the site as an HTML file
rvest::html_nodes( "a" )
html_page %>%  # read in the site as an HTML file
rvest::html_nodes( "a" ) %>% # return all nodes with links in them
rvest::html_attr( "href" )
html_page %>%  # read in the site as an HTML file
rvest::html_nodes( "a" ) %>% # return all nodes with links in them
rvest::html_attr( "href" ) -> sample.links
if( length( sample.links ) == 0 ){
return ( "No links scraped" )
}
getNodes <- function( input.URL ){
html_page <- xml2::read_html( input.URL )
sample.links <- html_page %>%  # read in the site as an HTML file
rvest::html_nodes( "a" ) %>% # return all nodes with links in them
rvest::html_attr( "href" )  # pulls out hypertext reference, links to other pages
# If there are no sample links pulled from the website, skip.
if( length( sample.links ) == 0 ){
return ( "No links scraped" )
}
return(sample.links)
}
getNodes(two)
sample.links <- html_page %>%  # read in the site as an HTML file
rvest::html_nodes( "a" )
View(sample.links)
sample.links <- html_page %>%  # read in the site as an HTML file
rvest::html_nodes( "a" ) %>% # return all nodes with links in them
rvest::html_attr( "href"
)
sample.links[[1]]
sample.links[[2]]
sample.links
sample.links <- html_page %>%  # read in the site as an HTML file
rvest::html_nodes( "a" ) %>% # return all nodes with links in them
rvest::html_attr( "href" )
grepl("http", sample.links)
grepl("http", sample.links)==T
grep("http", sample.links)
sample.links[grep("http", sample.links)]
sample.links
roxygen2::roxygenize()
library(webscraper)
load_test_urls()
test <- sample.urls$ORGURL[5]
one <- create_table(test)
roxygen2::roxygenize()
test
library(webscraper)
test <- "WWW.PORTLANDRFC.COM"
load <- create_table(test)
library(webscraper)
load <- create_table(test)
load <- create_table(c(test, test))
View(load)
test <- load$normalized_URL[1]
what <- get_p_node_data(test)
View(what)
what[336, "text"]
get_p_node_data <- function( input.URL ){
redirected.URL <- get_redirected_url( input.URL )
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
results.list <- NULL
results.df <- NULL
input.URL.list <-NULL
node.list <- NULL
xpath.list <- NULL
URL.list <- NULL
domain.list <- NULL
page.list <- NULL
text.list <- NULL
tag.list <- NULL
for ( i in 1:length(internal.links) ){
node.list[[i]] <- xml2::read_html(internal.links[i]) %>% xml2::xml_find_all('//*/p')
xpath.list[[i]] <- node.list[[i]] %>% xml2::xml_path()
text.list[[i]] <- node.list[[i]] %>% xml2::xml_text()
input.URL.list[[i]] <- rep(input.URL, length(text.list[[i]]))
URL.list[[i]] <- rep(internal.links[i], length(text.list[[i]]))
domain.list[[i]] <- rep(redirected.URL, length(text.list[[i]]))
page.list[[i]] <- rep(stringr::str_remove(internal.links[i], redirected.URL), length(text.list[[i]]))
tag.list[[i]] <- rep("p", length(text.list[[i]]))
results.list[[i]] <- dplyr::bind_cols(list(input.URL=input.URL.list[[i]], redirected.URL=domain.list[[i]], URL=URL.list[[i]], page=page.list[[i]], xpath=xpath.list[[i]], text=text.list[[i]], tag=tag.list[[i]]))
}
results.df <- dplyr::bind_rows( results.list ) %>%
mutate(text = str_squish( text ))
return( as.data.frame(results.df) )
}
what <- get_p_node_data(test)
get_p_node_data <- function( input.URL ){
redirected.URL <- get_redirected_url( input.URL )
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
results.list <- NULL
results.df <- NULL
input.URL.list <-NULL
node.list <- NULL
xpath.list <- NULL
URL.list <- NULL
domain.list <- NULL
page.list <- NULL
text.list <- NULL
tag.list <- NULL
for ( i in 1:length(internal.links) ){
node.list[[i]] <- xml2::read_html(internal.links[i]) %>% xml2::xml_find_all('//*/p')
xpath.list[[i]] <- node.list[[i]] %>% xml2::xml_path()
text.list[[i]] <- node.list[[i]] %>% xml2::xml_text()
input.URL.list[[i]] <- rep(input.URL, length(text.list[[i]]))
URL.list[[i]] <- rep(internal.links[i], length(text.list[[i]]))
domain.list[[i]] <- rep(redirected.URL, length(text.list[[i]]))
page.list[[i]] <- rep(stringr::str_remove(internal.links[i], redirected.URL), length(text.list[[i]]))
tag.list[[i]] <- rep("p", length(text.list[[i]]))
results.list[[i]] <- dplyr::bind_cols(list(input.URL=input.URL.list[[i]], redirected.URL=domain.list[[i]], URL=URL.list[[i]], page=page.list[[i]], xpath=xpath.list[[i]], text=text.list[[i]], tag=tag.list[[i]]))
}
results.df <- dplyr::bind_rows( results.list ) %>%
dplyr::mutate(text = str_squish( text ))
return( as.data.frame(results.df) )
}
what <- get_p_node_data(test)
get_p_node_data <- function( input.URL ){
redirected.URL <- get_redirected_url( input.URL )
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
results.list <- NULL
results.df <- NULL
input.URL.list <-NULL
node.list <- NULL
xpath.list <- NULL
URL.list <- NULL
domain.list <- NULL
page.list <- NULL
text.list <- NULL
tag.list <- NULL
for ( i in 1:length(internal.links) ){
node.list[[i]] <- xml2::read_html(internal.links[i]) %>% xml2::xml_find_all('//*/p')
xpath.list[[i]] <- node.list[[i]] %>% xml2::xml_path()
text.list[[i]] <- node.list[[i]] %>% xml2::xml_text()
input.URL.list[[i]] <- rep(input.URL, length(text.list[[i]]))
URL.list[[i]] <- rep(internal.links[i], length(text.list[[i]]))
domain.list[[i]] <- rep(redirected.URL, length(text.list[[i]]))
page.list[[i]] <- rep(stringr::str_remove(internal.links[i], redirected.URL), length(text.list[[i]]))
tag.list[[i]] <- rep("p", length(text.list[[i]]))
results.list[[i]] <- dplyr::bind_cols(list(input.URL=input.URL.list[[i]], redirected.URL=domain.list[[i]], URL=URL.list[[i]], page=page.list[[i]], xpath=xpath.list[[i]], text=text.list[[i]], tag=tag.list[[i]]))
}
results.df <- dplyr::bind_rows( results.list ) %>%
dplyr::mutate(text = stringr::str_squish( text ))
return( as.data.frame(results.df) )
}
what <- get_p_node_data(test)
View(what)
nchar(what$text)
get_p_node_data <- function( input.URL ){
redirected.URL <- get_redirected_url( input.URL )
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
results.list <- NULL
results.df <- NULL
input.URL.list <-NULL
node.list <- NULL
xpath.list <- NULL
URL.list <- NULL
domain.list <- NULL
page.list <- NULL
text.list <- NULL
tag.list <- NULL
for ( i in 1:length(internal.links) ){
node.list[[i]] <- xml2::read_html(internal.links[i]) %>% xml2::xml_find_all('//*/p')
xpath.list[[i]] <- node.list[[i]] %>% xml2::xml_path()
text.list[[i]] <- node.list[[i]] %>% xml2::xml_text()
input.URL.list[[i]] <- rep(input.URL, length(text.list[[i]]))
URL.list[[i]] <- rep(internal.links[i], length(text.list[[i]]))
domain.list[[i]] <- rep(redirected.URL, length(text.list[[i]]))
page.list[[i]] <- rep(stringr::str_remove(internal.links[i], redirected.URL), length(text.list[[i]]))
tag.list[[i]] <- rep("p", length(text.list[[i]]))
results.list[[i]] <- dplyr::bind_cols(list(input.URL=input.URL.list[[i]], redirected.URL=domain.list[[i]], URL=URL.list[[i]], page=page.list[[i]], xpath=xpath.list[[i]], text=text.list[[i]], tag=tag.list[[i]]))
}
results.df <- dplyr::bind_rows( results.list ) %>%
dplyr::mutate(text = stringr::str_squish( text )) %>%
dplyr::filter( nchar(text) > 0 )
return( as.data.frame(results.df) )
}
what <- get_p_node_data(test)
roxygen2::roxygenize()
library(webscraper)
load_test_urls()
one <- sample.urls$ORGURL[1]
test <- create_table(one)
one <- sample.urls$ORGURL[5]
test <- create_table(one)
links <- get_links(test$normalized_URL)
text <- get_p_node_data(test$normalized_URL)
library(webscraper)
load_test_urls()
test <- sample.urls$ORGURL[4]
create_table(test)
done <- test
done <- create_table(test)
nodes <- get_p_node_data(done$normalized_URL[1])
View(nodes)
get_p_node_data <- function( input.URL ){
redirected.URL <- get_redirected_url( input.URL )
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
results.list <- NULL
results.df <- NULL
input.URL.list <-NULL
node.list <- NULL
xpath.list <- NULL
URL.list <- NULL
domain.list <- NULL
page.list <- NULL
text.list <- NULL
tag.list <- NULL
for ( i in 1:length(internal.links) ){
node.list[[i]] <- xml2::read_html(internal.links[i]) %>% xml2::xml_find_all('//*/p')
xpath.list[[i]] <- node.list[[i]] %>% xml2::xml_path()
text.list[[i]] <- node.list[[i]] %>% xml2::xml_text()
input.URL.list[[i]] <- rep(input.URL, length(text.list[[i]]))
URL.list[[i]] <- rep(internal.links[i], length(text.list[[i]]))
domain.list[[i]] <- rep(redirected.URL, length(text.list[[i]]))
page.list[[i]] <- rep(stringr::str_remove(internal.links[i], redirected.URL), length(text.list[[i]]))
tag.list[[i]] <- rep("p", length(text.list[[i]]))
results.list[[i]] <- dplyr::bind_cols(list(input.URL=input.URL.list[[i]], redirected.URL=domain.list[[i]], URL=URL.list[[i]], page=page.list[[i]], xpath=xpath.list[[i]], text=text.list[[i]], tag=tag.list[[i]]))
}
results.df <- dplyr::bind_rows( results.list ) %>%
dplyr::mutate(text = stringr::str_squish( text )) %>%
dplyr::filter( nchar(text) > 0 )
return( as.data.frame(results.df) )
}
nodes <- get_p_node_data(done$normalized_URL[1])
View(nodes)
table(nchar(nodes$text))
nchar(nodes[9, "text"])
View(done)
library(webscraper)
load_test_urls()
create_table(sample.urls$ORGURL[1])
??GET
library(webscraper)
load_test_urls()
create_table(sample.urls$ORGURL[1])
create_table(sample.urls$ORGURL[1:2])
x <- create_table(sample.urls$ORGURL[1:5])
x <- create_table(sample.urls$ORGURL[1:10])
input.URL <- kmhstrackfield.com
input.URL <- "kmhstrackfield.com"
original_URL <- input.URL
normalized_URL <- normalize_url( input.URL )
httr::http_error( normalized_URL )
original_URL
httr::GET(original_URL)
check_url_status(original_URL)
library(webscraper)
load_test_urls()
x <- create_table(sample.urls$ORGURL[1:10])
library(webscraper)
load_test_urls()
x <- create_table(sample.urls$ORGURL[1:10])
View(sample.urls)
input.URL <- "WWW.KMHSTRACKFIELD.COM"
original_URL <- input.URL
normalized_URL <- normalize_url( input.URL )
check_url_status( normalized_URL ) == "DNE"
Error <- ifelse(check_url_status( normalized_URL ) == "DNE", "Does not exist", httr::status_code( httr::GET( normalized_URL ) ))
httr::http_error( normalized_URL ) == TRUE | check_url_status( normalized_URL ) == "DNE"
normalize_url( input.URL )
library(webscraper)
original_URL <- input.URL
normalized_URL <- normalize_url( input.URL )
original_URL <- input.URL
normalized_URL <- normalize_url( input.URL )
url_status <- check_url_status( normalized_URL )
if(url_status == "DNE"){
result <- data.frame( original_URL,
normalized_URL = NA,
redirected_URL = NA,
root_URL = NA,
active_URL = NA,
url_version = NA,
domain_status = "URL does not exist")
}else if(httr::http_error( normalized_URL ) == TRUE ){
result <- data.frame( original_URL,
normalized_URL = NA,
redirected_URL = NA,
root_URL = NA,
active_URL = NA,
url_version = NA,
domain_status = paste("Error:", httr::status_code( httr::GET( normalized_URL ) )))
}else{
http_status_code <- httr::GET( normalized_URL )$all_headers[[1]]$status
is_redirected <- as.integer( http_status_code/100 ) == 3
redirected_URL <- ifelse( is_redirected, get_redirected_url( normalized_URL ), NA )
root_URL <- create_root_url( normalized_URL )
active_URL <- NA
url_version <- NA
domain_status <- NA
if( check_url_status( original_URL ) == "VALID" ){
active_URL <- original_URL
url_version <- "original"
domain_status <- check_url_status( original_URL )
} else if( check_url_status( normalized_URL ) == "VALID" ){
active_URL <- normalized_URL
url_version <- "normalized"
domain_status <- check_url_status( normalized_URL )
} else if( is_redirected ){
if( check_url_status( redirected_URL ) == "VALID" ){
active_URL <- redirected_URL
url_version <- "redirect"
domain_status <- check_url_status( redirected_URL )
}
} else{
if( check_url_status( root_URL ) == "VALID" ){
active_URL <- root_URL
url_version <- "root"
domain_status <- check_url_status( root_URL )
}
result <- data.frame( original_URL,
normalized_URL,
redirected_URL,
root_URL,
active_URL,
url_version,
domain_status )
}
return( result )
x <- create_table(sample.urls$ORGURL[5])
x <- create_table(sample.urls$ORGURL[6])
View(x)
x <- create_table(sample.urls$ORGURL[1:10])
View(x)
check_url_status(sample.urls$ORGURL[1])
RCurl::url.exists( input.URL )
RCurl::url.exists( sample.urls$ORGURL[1] )
RCurl::url.exists( sample.urls$ORGURL[2] )
RCurl::url.exists( sample.urls$ORGURL[4] )
RCurl::url.exists( "https://www.bacasmaine.org" )
?url.exists
RCurl::url.exists("https://www.bacasmaine.org")
try(open.connection(input.URL,open="rt",timeout=t),silent=T)
xx <- try(open.connection(input.URL,open="rt",timeout=t),silent=T)
xx <- try(open.connection(sample.urls$ORGURL[1],open="rt",timeout=t),silent=T)
xx <- try(open.connection(sample.urls$ORGURL[2],open="rt",timeout=t),silent=T)
xx <- try(open.connection(sample.urls$ORGURL[3],open="rt",timeout=t),silent=T)
tryCatch(normalize_url(normalized_URL))
tryCatch(httr::check_url_status(normalized_URL))
tryCatch(httr::http_error(normalized_URL))
??url.exists
x <- httr::http_error( normalized_URL )
x <- try(httr::http_error( normalized_URL ))
x <- try(httr::http_error( normalized_URL ), silent = T)
x
x <- try(httr::http_error( normalized_URL ), silent = T)[1]
x <- try(httr::http_error( normalized_URL ), silent = T)
class(x)
input.URL <- sample.urls[4]
input.URL <- sample.urls$ORGURL[4]
original_URL <- input.URL
normalized_URL <- normalize_url( input.URL )
url_status <- try(httr::http_error( normalized_URL ), silent = T)
class(url_status)
library(webscraper)
x <- create_table(sample.urls$ORGURL[1:10])
View(x)
input.URL <- "WWW.WBE-PTO.ORG
"
input.URL <- "WWW.WBE-PTO.ORG"
original_URL <- input.URL
normalized_URL <- normalize_url( input.URL )
url_status <- try(httr::http_error( normalized_URL ), silent = T)
normalized_URL
link <- x$normalized_URL[7]
link <- x$normalized_URL[8]
input.URL <- link
redirected.URL <- get_redirected_url( input.URL )
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
results.list <- NULL
results.df <- NULL
input.URL.list <-NULL
node.list <- NULL
xpath.list <- NULL
URL.list <- NULL
domain.list <- NULL
page.list <- NULL
text.list <- NULL
tag.list <- NULL
node.list[[i]] <- xml2::read_html(internal.links[i])
node.list[[i]] <- xml2::read_html(internal.links[1])
node.list[[1]] <- xml2::read_html(internal.links[1])
View(node.list)
length(internal.links)
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
node.list[[i]] <- xml2::read_html(internal.links[i])
i <-5
node.list[[i]] <- xml2::read_html(internal.links[i])
View(node.list)
xml_child(node.list[[5]], 1)
xml_child(node.list[[5]], 2)
xml_attrs(node.list[[5]])
y <- get_p_node_data(x$normalized_URL[8])
View(x)
y <- get_p_node_data(x$normalized_URL[2])
redirected.URL <- get_redirected_url( input.URL )
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
results.list <- NULL
results.df <- NULL
input.URL.list <-NULL
node.list <- NULL
xpath.list <- NULL
URL.list <- NULL
domain.list <- NULL
page.list <- NULL
text.list <- NULL
tag.list <- NULL
for ( i in 1:length(internal.links) ){
node.list[[i]] <- xml2::read_html(internal.links[i]) %>% xml2::xml_find_all('//*/p')
xpath.list[[i]] <- node.list[[i]] %>% xml2::xml_path()
text.list[[i]] <- node.list[[i]] %>% xml2::xml_text()
input.URL.list[[i]] <- rep(input.URL, length(text.list[[i]]))
URL.list[[i]] <- rep(internal.links[i], length(text.list[[i]]))
domain.list[[i]] <- rep(redirected.URL, length(text.list[[i]]))
page.list[[i]] <- rep(stringr::str_remove(internal.links[i], redirected.URL), length(text.list[[i]]))
tag.list[[i]] <- rep("p", length(text.list[[i]]))
results.list[[i]] <- dplyr::bind_cols(list(input.URL=input.URL.list[[i]], redirected.URL=domain.list[[i]], URL=URL.list[[i]], page=page.list[[i]], xpath=xpath.list[[i]], text=text.list[[i]], tag=tag.list[[i]]))
}
results.df <- dplyr::bind_rows( results.list ) %>%
dplyr::mutate(text = stringr::str_squish( text )) %>%
dplyr::filter( nchar(text) > 0 )
View(results.df)
library(webscraper)
y <- get_p_node_data(x$normalized_URL[2])
input.URL <- x$normalized_URL[2]
redirected.URL <- get_redirected_url( input.URL )
internal.links <- Rcrawler::LinkExtractor(url = redirected.URL)$InternalLinks
results.list <- NULL
results.df <- NULL
input.URL.list <-NULL
node.list <- NULL
xpath.list <- NULL
URL.list <- NULL
domain.list <- NULL
page.list <- NULL
text.list <- NULL
tag.list <- NULL
for ( i in 1:length(internal.links) ){
if(httr::http_error( i ) == TRUE ){next}
node.list[[i]] <- xml2::read_html(internal.links[i]) %>% xml2::xml_find_all('//*/p')
xpath.list[[i]] <- node.list[[i]] %>% xml2::xml_path()
text.list[[i]] <- node.list[[i]] %>% xml2::xml_text()
input.URL.list[[i]] <- rep(input.URL, length(text.list[[i]]))
URL.list[[i]] <- rep(internal.links[i], length(text.list[[i]]))
domain.list[[i]] <- rep(redirected.URL, length(text.list[[i]]))
page.list[[i]] <- rep(stringr::str_remove(internal.links[i], redirected.URL), length(text.list[[i]]))
tag.list[[i]] <- rep("p", length(text.list[[i]]))
results.list[[i]] <- dplyr::bind_cols(list(input.URL=input.URL.list[[i]], redirected.URL=domain.list[[i]], URL=URL.list[[i]], page=page.list[[i]], xpath=xpath.list[[i]], text=text.list[[i]], tag=tag.list[[i]]))
}
for ( i in 1:length(internal.links) ){
if(httr::http_error( internal.links[i] ) == TRUE ){next}
node.list[[i]] <- xml2::read_html(internal.links[i]) %>% xml2::xml_find_all('//*/p')
xpath.list[[i]] <- node.list[[i]] %>% xml2::xml_path()
text.list[[i]] <- node.list[[i]] %>% xml2::xml_text()
input.URL.list[[i]] <- rep(input.URL, length(text.list[[i]]))
URL.list[[i]] <- rep(internal.links[i], length(text.list[[i]]))
domain.list[[i]] <- rep(redirected.URL, length(text.list[[i]]))
page.list[[i]] <- rep(stringr::str_remove(internal.links[i], redirected.URL), length(text.list[[i]]))
tag.list[[i]] <- rep("p", length(text.list[[i]]))
results.list[[i]] <- dplyr::bind_cols(list(input.URL=input.URL.list[[i]], redirected.URL=domain.list[[i]], URL=URL.list[[i]], page=page.list[[i]], xpath=xpath.list[[i]], text=text.list[[i]], tag=tag.list[[i]]))
}
